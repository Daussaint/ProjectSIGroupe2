{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion detection using CNN \n",
    "## B) Testing model with camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "import sklearn.externals\n",
    "import joblib\n",
    "import h5py\n",
    "from tkinter import *\n",
    "import tensorflow as tf\n",
    "from PIL import ImageTk, Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Loading the model with H5PY & the face detectcion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model_emotion_detection.h5')\n",
    "face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Program performing emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\romai\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-3-290c30165af3>\", line 63, in open_webcam\n",
      "    converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "cv2.error: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
      "\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\romai\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-3-290c30165af3>\", line 63, in open_webcam\n",
      "    converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "cv2.error: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
      "\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\romai\\anaconda3\\lib\\tkinter\\__init__.py\", line 1883, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-3-290c30165af3>\", line 63, in open_webcam\n",
      "    converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
      "cv2.error: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creer une fenetre\n",
    "window = Tk()\n",
    " \n",
    "# Personnaliser la fenetre\n",
    "window.title(\"Emotion recognition\")\n",
    "window.geometry(\"1200x720\")\n",
    "window.config(background = \"darkblue\")\n",
    " \n",
    "# Premier texte\n",
    "label_title = Label(window, text = \"Present your face in front of the webcam and click on Start button\", font = (\"Arial\", 25), bg = \"darkblue\", fg = \"white\")\n",
    "label_title.pack() #pour afficher le titre\n",
    " \n",
    "# Second texte\n",
    "label_subtitle = Label(window, text = \"Here's your average emotion : \", font = (\"Arial\", 20), bg = \"darkblue\", fg = \"white\")\n",
    "label_subtitle.pack(expand = YES) #pour afficher le titre\n",
    "\n",
    "# Definition de variables qui vont nous aider pour le programme\n",
    "global activation_sytem\n",
    "activation_sytem = 0 \n",
    "\n",
    "global nbr_iteration\n",
    "nbr_iteration = 0\n",
    "\n",
    "global del_label\n",
    "del_label = 0\n",
    "\n",
    "# Fonction d'activation de la webcam et du code de reconnaissance facial correspondant\n",
    "def open_webcam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    activation_sytem = 1\n",
    "    nbr_iteration = 0\n",
    "    predictions_sum = [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
    "    \n",
    "    # Variable del_label qui, une fois au dessus de 1, permettra d'éffacer le contenu des Labels de l'interface dans le but de refaire le test de reconnaissance\n",
    "    global del_label\n",
    "    if del_label > 0:\n",
    "        global label_subsubtitle1\n",
    "        label_subsubtitle1.destroy()\n",
    "        global label_subsubtitle2\n",
    "        label_subsubtitle2.destroy()\n",
    "        global label_subsubtitle3\n",
    "        label_subsubtitle3.destroy()\n",
    "        global label_subsubtitle4\n",
    "        label_subsubtitle4.destroy()\n",
    "        global label_subsubtitle5\n",
    "        label_subsubtitle5.destroy()\n",
    "        global label_subsubtitle6\n",
    "        label_subsubtitle6.destroy()\n",
    "        global label_subsubtitle7\n",
    "        label_subsubtitle7.destroy()\n",
    "        global label_subtitle8\n",
    "        label_subtitle8.destroy()\n",
    "        \n",
    "    if del_label == 0:\n",
    "        del_label = 1\n",
    "    \n",
    "    # Partie de code lisant le contenu de la webcam et qui attribue une émotion à ce contenu\n",
    "    while activation_sytem == 1:\n",
    "        \n",
    "        # Lecture de la webcam\n",
    "        ret,image = cap.read()\n",
    "        # convertion de l'image en niveau de gris\n",
    "        converted_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Detection du visage sur l'image\n",
    "        faces_detected = face_haar_cascade.detectMultiScale(converted_image,scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        for (x,y,w,h) in faces_detected:\n",
    "            \n",
    "            # Dessin du rectangle autour du visage\n",
    "            cv2.rectangle(image,(x,y), (x+w,y+h), (255,0,0))\n",
    "            # Calibration de l'image en 48x48 pixels\n",
    "            roi_gray = converted_image[y:y+w,x:x+h]\n",
    "            roi_gray = cv2.resize(roi_gray,(48,48))\n",
    "            \n",
    "            # Transformation de l'image en un array\n",
    "            image_pixels = tf.keras.preprocessing.image.img_to_array(roi_gray)\n",
    "            image_pixels = np.expand_dims(image_pixels, axis = 0)\n",
    "            image_pixels /= 255\n",
    "            \n",
    "            # Prédiction par le model\n",
    "            predictions = model.predict(image_pixels) \n",
    "            max_index = np.argmax(predictions[0])\n",
    "            \n",
    "            # Attibution de l'émotion (en string) correspondant à la prédiction du model\n",
    "            emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "            emotion_prediction = emotion_detection[max_index]\n",
    "            \n",
    "            #calcul de la somme des probabilités correspondant à chaque émotion\n",
    "            predictions_sum[0][0] = predictions_sum[0][0] + predictions[0][0]\n",
    "            predictions_sum[0][1] = predictions_sum[0][1] + predictions[0][1]\n",
    "            predictions_sum[0][2] = predictions_sum[0][2] + predictions[0][2]\n",
    "            predictions_sum[0][3] = predictions_sum[0][3] + predictions[0][3]\n",
    "            predictions_sum[0][4] = predictions_sum[0][4] + predictions[0][4]\n",
    "            predictions_sum[0][5] = predictions_sum[0][5] + predictions[0][5]\n",
    "            predictions_sum[0][6] = predictions_sum[0][6] + predictions[0][6]\n",
    "            \n",
    "            # Incrémentation de la variable pour connaître le nombre d'itération effectué et ensuite pouvoir faire une moyenne des émotions\n",
    "            nbr_iteration = nbr_iteration + 1\n",
    "            \n",
    "            # Détermination de la police d'écriture\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # Emplacement et propriétés du text \"Emotion\" placé sur l'image\n",
    "            cv2.putText(image, emotion_prediction, (int(x), int(y)), font, 3, (0, 0, 255), 2, cv2.LINE_4)\n",
    "            \n",
    "            # Affichage de l'image/vidéo\n",
    "            cv2.imshow('Demo video', image)\n",
    "    \n",
    "           \n",
    "            # Arrêt de la démonstration une fois avoir atteint le nombre de 60 itérations\n",
    "            if cv2.waitKey(2) & nbr_iteration == 60:\n",
    "                \n",
    "                # Arret de l'utilisation de la webcam\n",
    "                cap.release()\n",
    "                \n",
    "                # calcul de la moyenne des prédictions de chaque émotions sur l'entierté de la démonstration\n",
    "                moyenne_angry = (predictions_sum[0][0]/nbr_iteration)*100\n",
    "                mo_angry = round(moyenne_angry,1)\n",
    "                \n",
    "                moyenne_disgust = (predictions_sum[0][1]/nbr_iteration)*100\n",
    "                mo_disgust = round(moyenne_disgust,1)\n",
    "                \n",
    "                moyenne_fear = (predictions_sum[0][2]/nbr_iteration)*100\n",
    "                mo_fear = round(moyenne_fear,1)\n",
    "                \n",
    "                moyenne_happy = (predictions_sum[0][3]/nbr_iteration)*100\n",
    "                mo_happy = round(moyenne_happy,1)\n",
    "                \n",
    "                moyenne_sad = (predictions_sum[0][4]/nbr_iteration)*100\n",
    "                mo_sad = round(moyenne_sad,1)\n",
    "                \n",
    "                moyenne_surprise = (predictions_sum[0][5]/nbr_iteration)*100\n",
    "                mo_surprise = round(moyenne_surprise,1)\n",
    "                \n",
    "                moyenne_neutral = (predictions_sum[0][6]/nbr_iteration)*100\n",
    "                mo_neutral = round(moyenne_neutral,1)\n",
    "                \n",
    "                #Determination de l'émotion dominante\n",
    "                tab_moyenne = [[mo_angry, mo_disgust, mo_fear, mo_happy, mo_sad, mo_surprise, mo_neutral]]\n",
    "                max_moy = np.argmax(tab_moyenne[0])\n",
    "                dominant = emotion_detection[max_moy]\n",
    "                \n",
    "                #Affichage de ces moyennes sur l'interface\n",
    "                label_subsubtitle1 = Label(window, text = ('angry', mo_angry,'%') , font = (\"Arial\", 20), bg = \"darkblue\", fg = \"white\")\n",
    "                label_subsubtitle2 = Label(window, text = ('disgust', mo_disgust,'%') , font = (\"Arial\", 20), bg = \"darkblue\", fg = \"white\")\n",
    "                label_subsubtitle3 = Label(window, text = ('fear', mo_fear,'%') , font = (\"Arial\", 20), bg = \"darkblue\", fg = \"white\")\n",
    "                label_subsubtitle4 = Label(window, text = ('happy', mo_happy,'%') , font = (\"Arial\", 20), bg = \"darkblue\", fg = \"white\")\n",
    "                label_subsubtitle5 = Label(window, text = ('sad', mo_sad,'%') , font = (\"Arial\", 20), bg = \"darkblue\", fg = \"white\")\n",
    "                label_subsubtitle6 = Label(window, text = ('surprise', mo_surprise,'%') , font = (\"Arial\", 20), bg = \"darkblue\", fg = \"white\")\n",
    "                label_subsubtitle7 = Label(window, text = ('neutral', mo_neutral,'%') , font = (\"Arial\", 20), bg = \"darkblue\", fg = \"white\")\n",
    "                \n",
    "                label_subsubtitle1.pack(expand = YES) \n",
    "                label_subsubtitle2.pack(expand = YES) \n",
    "                label_subsubtitle3.pack(expand = YES)\n",
    "                label_subsubtitle4.pack(expand = YES)\n",
    "                label_subsubtitle5.pack(expand = YES)\n",
    "                label_subsubtitle6.pack(expand = YES)\n",
    "                label_subsubtitle7.pack(expand = YES)\n",
    "                \n",
    "                #Affichage de l'émotion dominante sur l'interface\n",
    "                label_subtitle8 = Label(window, text = ('Dominant:', dominant) , font = (\"Arial\", 30), bg = \"darkblue\", fg = \"red\")\n",
    "                label_subtitle8.pack(expand = YES) #pour afficher le titre\n",
    "                \n",
    "                # Fermeture de la fenêtre contenant la webcam\n",
    "                cv2.destroyAllWindows()\n",
    "                \n",
    "                # Arrêt de la boucle for\n",
    "                break\n",
    "               \n",
    "# Fonction Stop permettant la fermeture de la fenêtre d'interface\n",
    "def stop():\n",
    "    activation_sytem=0\n",
    "    window.destroy()\n",
    "        \n",
    "#  Ajout des boutons Start et Close permettant donc de lancer la démonstration et de fermer la fenêtre d'interface\n",
    "button_Stop = Button(window, text = \"Close\", font =(\"Arial\", 20), bg = 'white', fg = 'darkblue', command = stop)\n",
    "button_Stop.pack(side = BOTTOM, fill = X, expand = False)\n",
    "\n",
    "button_Start = Button(window, text = \"Start\", font =(\"Arial\", 20), bg = 'white', fg = 'darkblue', command = open_webcam)\n",
    "button_Start.pack(side = BOTTOM, fill = X, expand = False)\n",
    "\n",
    "# Affichage de l'interface\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source :\n",
    "- https://analyticsindiamag.com/my-first-cnn-project-emotion-detection-using-convolutional-neural-network-with-tpu/\n",
    "\n",
    "- https://www.youtube.com/watch?v=DtBu1u5aBsc&t=2363s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
